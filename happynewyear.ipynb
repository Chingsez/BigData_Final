{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. STORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset stories\n",
    "data_df = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://xinyuwang/finalproject/story.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----+------------+--------------------+--------------------+--------------------+--------------------+-------+----+-----------+------------+\n",
      "|     id|          by|score|        time|             time_ts|               title|                 url|                text|deleted|dead|descendants|      author|\n",
      "+-------+------------+-----+------------+--------------------+--------------------+--------------------+--------------------+-------+----+-----------+------------+\n",
      "|6940813|   sarath237|  0.0|1387536270.0|2013-12-20 10:44:...| Sheryl Brindo Ho...|http://www.youtub...| Sheryl Brindo Ho...|   null|True|       null|   sarath237|\n",
      "|6991401|123123321321|  0.0|1388508751.0|2013-12-31 16:52:...|Are you people al...|                null|They&#x27;re pret...|   null|True|       null|123123321321|\n",
      "|1531556|         ssn|  0.0|1279617234.0|2010-07-20 09:13:...|New UI for Google...|http://googlesyst...|Again following o...|   null|null|        0.0|         ssn|\n",
      "|5012398|        hoju|  0.0|1357387877.0|2013-01-05 12:11:...|Historic website ...|http://webscrapin...|Python script to ...|   null|null|        0.0|        hoju|\n",
      "|7214182|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|1187303|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|1318494|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|3700400|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|1384487|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|3530428|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|3538851|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|4167497|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|3789206|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|4072660|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|2979883|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|3300974|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|2305819|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|3833628|       kogir|  0.0|1401561740.0|2014-05-31 18:42:...|         Placeholder|                null|       Mind the gap.|   null|null|        0.0|       kogir|\n",
      "|2606988|       ramis|  0.0|1306931771.0|2011-06-01 12:36:...|Kidney Transplant...|http://dhshahzad....|I started indepen...|   null|True|        0.0|       ramis|\n",
      "|4542754|       tette|  0.0|1348045069.0|2012-09-19 08:57:...|Bouncing Marble f...|http://www.window...|Bouncing marble i...|   null|null|        0.0|       tette|\n",
      "+-------+------------+-----+------------+--------------------+--------------------+--------------------+--------------------+-------+----+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- by: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- time_ts: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- deleted: string (nullable = true)\n",
      " |-- dead: string (nullable = true)\n",
      " |-- descendants: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069464"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "story_df = data_df.select(data_df['id'].cast(IntegerType()),\n",
    "                     data_df['score'].cast(IntegerType()),\n",
    "                     #data_df[\"time\"],\n",
    "                     data_df['time_ts'].cast('timestamp'),\n",
    "                     data_df['title'],\n",
    "                     #data_df['type'],\n",
    "                     data_df['url'],\n",
    "                     data_df['text'],\n",
    "                     #data_df['parent'].cast(IntegerType()),\n",
    "                     #data_df['deleted'],\n",
    "                     #data_df['dead'],\n",
    "                     data_df['descendants'].cast(IntegerType()),\n",
    "                     #data_df['id'].cast(IntegerType()),\n",
    "                     data_df['author']\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- time_ts: timestamp (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- descendants: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------------------+--------------------+--------------------+--------------------+-----------+------------+\n",
      "|     id|score|            time_ts|               title|                 url|                text|descendants|      author|\n",
      "+-------+-----+-------------------+--------------------+--------------------+--------------------+-----------+------------+\n",
      "|6940813|    0|2013-12-20 10:44:30| Sheryl Brindo Ho...|http://www.youtub...| Sheryl Brindo Ho...|       null|   sarath237|\n",
      "|6991401|    0|2013-12-31 16:52:31|Are you people al...|                null|They&#x27;re pret...|       null|123123321321|\n",
      "|1531556|    0|2010-07-20 09:13:54|New UI for Google...|http://googlesyst...|Again following o...|          0|         ssn|\n",
      "|5012398|    0|2013-01-05 12:11:17|Historic website ...|http://webscrapin...|Python script to ...|          0|        hoju|\n",
      "|7214182|    0|2014-05-31 18:42:20|         Placeholder|                null|       Mind the gap.|          0|       kogir|\n",
      "|1187303|    0|2014-05-31 18:42:20|         Placeholder|                null|       Mind the gap.|          0|       kogir|\n",
      "|1318494|    0|2014-05-31 18:42:20|         Placeholder|                null|       Mind the gap.|          0|       kogir|\n",
      "|3700400|    0|2014-05-31 18:42:20|         Placeholder|                null|       Mind the gap.|          0|       kogir|\n",
      "|1384487|    0|2014-05-31 18:42:20|         Placeholder|                null|       Mind the gap.|          0|       kogir|\n",
      "|3530428|    0|2014-05-31 18:42:20|         Placeholder|                null|       Mind the gap.|          0|       kogir|\n",
      "+-------+-----+-------------------+--------------------+--------------------+--------------------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp table\n",
    "story_df.createOrReplaceTempView('ini_story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1959840"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_df.select(\"id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_df.select(\"title\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1925929"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_df.select(\"time_ts\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_story_df = spark.sql('select * from ini_story where time_ts is not NULL and title is not NULL and author is not NULL and score is not NULL')\n",
    "clean_story_df.createOrReplaceTempView('story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = spark.sql('select * from ini_story where url is not NULL and time_ts is not NULL and title is not NULL and author is not NULL and score is not NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df.createOrReplaceTempView('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'([a-z]+).(com|net)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('efficientsoftware', 'net')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern, 'http://www.efficientsoftware.net/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlStatement = \"\"\"\n",
    "SELECT id, regexp_extract(url, '([a-z]+).(com|net|co|cn|org|ru|de|br|uk|pl|ir|it|in|fr|au|jp|info)', 1) as web\n",
    "FROM url \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df1 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|     id|              web|\n",
      "+-------+-----------------+\n",
      "|6940813|          youtube|\n",
      "|1531556|         blogspot|\n",
      "|5012398|      webscraping|\n",
      "|2606988|         blogspot|\n",
      "|4542754|     windowsphone|\n",
      "|4824675|       abiquolabs|\n",
      "|1120285|       datingsite|\n",
      "|5221577|        nobugware|\n",
      "|4827038|   allelectronics|\n",
      "|4481018|         blogspot|\n",
      "|7061983|efficientsoftware|\n",
      "|1215015|       technobuzz|\n",
      "|1505655|         zohmuomo|\n",
      "|4673231| gumrukmusaviritr|\n",
      "|1503352|       roadtickle|\n",
      "|1540745|      kronikmedia|\n",
      "|1370228|       fastessays|\n",
      "|5917267|     sextoysbrand|\n",
      "|5969633|    matthewaperry|\n",
      "| 124722|             blog|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_df1.createOrReplaceTempView('url2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlStatement = \"\"\"\n",
    "SELECT web\n",
    "FROM url2\n",
    "WHERE web != ''\n",
    "\"\"\"\n",
    "url_df2 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1657898"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlStatement = \"\"\"\n",
    "SELECT COUNT(id) AS num, web\n",
    "FROM url2\n",
    "WHERE web != '' and web != 'www'\n",
    "GROUP BY web\n",
    "ORDER BY num DESC\n",
    "\"\"\"\n",
    "url_df3 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|  num|            web|\n",
      "+-----+---------------+\n",
      "|36296|         github|\n",
      "|30887|     techcrunch|\n",
      "|30856|        youtube|\n",
      "|28325|       blogspot|\n",
      "|27659|        nytimes|\n",
      "|18549|         medium|\n",
      "|17192|         google|\n",
      "|14755|            bbc|\n",
      "|13796|    arstechnica|\n",
      "|13624|          wired|\n",
      "|12499|      wordpress|\n",
      "| 8582|      wikipedia|\n",
      "| 8156|businessinsider|\n",
      "| 7434|         forbes|\n",
      "| 7276|             on|\n",
      "| 7183|           blog|\n",
      "| 7110|       mashable|\n",
      "| 7068|    venturebeat|\n",
      "| 6812|     thenextweb|\n",
      "| 6749|       theverge|\n",
      "+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story distribution in terms of time\n",
    "# What is the trend of story numbers from 2006-2016 in Hacker News?\n",
    "\n",
    "sqlStatement = \"\"\"\n",
    "SELECT COUNT(id) AS story_num, \n",
    "year(time_ts) as year\n",
    "FROM story\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "\"\"\"\n",
    "story_time_df1 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|story_num|year|\n",
      "+---------+----+\n",
      "|       50|2006|\n",
      "|    21948|2007|\n",
      "|    68877|2008|\n",
      "|   109468|2009|\n",
      "|   175246|2010|\n",
      "|   285433|2011|\n",
      "|   305361|2012|\n",
      "|   303813|2013|\n",
      "|   287287|2014|\n",
      "|   250348|2015|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story_time_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story distribution in terms of time\n",
    "# What is the most popular/active time during a day in pubulishing a story?\n",
    "\n",
    "sqlStatement = \"\"\"\n",
    "SELECT COUNT(id) AS story_num, \n",
    "hour(time_ts) as hour\n",
    "FROM story\n",
    "GROUP BY hour\n",
    "ORDER BY story_num DESC\n",
    "\"\"\"\n",
    "story_time_df2 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|story_num|hour|\n",
      "+---------+----+\n",
      "|   118330|  16|\n",
      "|   116519|  17|\n",
      "|   114846|  15|\n",
      "|   111187|  18|\n",
      "|   107289|  14|\n",
      "|   101710|  19|\n",
      "|    95143|  20|\n",
      "|    92281|  13|\n",
      "|    87559|  21|\n",
      "|    75879|  12|\n",
      "|    75403|  22|\n",
      "|    64806|  23|\n",
      "|    62944|  11|\n",
      "|    58054|   0|\n",
      "|    55560|  10|\n",
      "|    54969|   1|\n",
      "|    54117|   9|\n",
      "|    53419|   2|\n",
      "|    52016|   3|\n",
      "|    51697|   6|\n",
      "|    51264|   8|\n",
      "|    51254|   4|\n",
      "|    50800|   7|\n",
      "|    50785|   5|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story_time_df2.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(score)=0, max(score)=75248, avg(score)=10.447452950680841)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score information\n",
    "# what is the average score of those story?\n",
    "spark.sql(\"select min(score),max(score),avg(score) from story\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author/user information \n",
    "# decending by total_score \n",
    "sqlStatement = \"\"\"SELECT SUM(score) as total_score,author,\n",
    "SUM(descendants) as total_decendants,\n",
    "count(id) as total_stories\n",
    "FROM story\n",
    "GROUP BY author\n",
    "ORDER BY total_score DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "user_df = spark.sql(sqlStatement)\n",
    "#user_df.createOrReplaceTempView(\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------------+-------------+\n",
      "|total_score|     author|total_decendants|total_stories|\n",
      "+-----------+-----------+----------------+-------------+\n",
      "|      76851|ColinWright|           30700|         3726|\n",
      "|      75248|          0|         1732237|            0|\n",
      "|      64156| shawndumas|           25926|         6585|\n",
      "|      59958|    llambda|           20324|         2595|\n",
      "|      56798|      fogus|           21136|         2412|\n",
      "|      53452|      danso|           22792|         2610|\n",
      "|      52701|       cwan|           24067|         7059|\n",
      "|      51836|        luu|           19713|         2265|\n",
      "|      49003|  ssclafani|           24026|         1324|\n",
      "|      41601|      evo_9|           16215|         5635|\n",
      "+-----------+-----------+----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author/user information \n",
    "# decending by total_stories \n",
    "sqlStatement = \"\"\"SELECT SUM(score) as total_score, author,\n",
    "SUM(descendants) as total_decendants,\n",
    "count(id) as total_stories\n",
    "FROM story\n",
    "GROUP BY author\n",
    "ORDER BY total_stories DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "user_df2 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------------+-------------+\n",
      "|total_score|     author|total_decendants|total_stories|\n",
      "+-----------+-----------+----------------+-------------+\n",
      "|      52701|       cwan|           24067|         7059|\n",
      "|      64156| shawndumas|           25926|         6585|\n",
      "|      41601|      evo_9|           16215|         5635|\n",
      "|      29477|      nickb|           11804|         4303|\n",
      "|      26431|   iProject|           11759|         4262|\n",
      "|      28454|   bootload|           11351|         4158|\n",
      "|      29598|     edw519|           13726|         3823|\n",
      "|      76851|ColinWright|           30700|         3726|\n",
      "|      29806|     nreece|           12554|         3713|\n",
      "|      36511| tokenadult|           20190|         3634|\n",
      "+-----------+-----------+----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author/user information \n",
    "# decending by avg_score \n",
    "sqlStatement = \"\"\"SELECT SUM(score) as total_score, author,\n",
    "SUM(descendants) as total_decendants, SUM(score)/count(id) as avg_score,\n",
    "count(id) as total_stories\n",
    "FROM story\n",
    "GROUP BY author\n",
    "ORDER BY avg_score DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "user_df3 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+----------------+---------+-------------+\n",
      "|total_score|         author|total_decendants|avg_score|total_stories|\n",
      "+-----------+---------------+----------------+---------+-------------+\n",
      "|       1543|    realfuncode|             526|   1543.0|            1|\n",
      "|       2905|     frederfred|             412|   1452.5|            2|\n",
      "|       1344| themanthatfell|             407|   1344.0|            1|\n",
      "|       1282|          rcina|             249|   1282.0|            1|\n",
      "|       1257|         kvargs|             558|   1257.0|            1|\n",
      "|       1248|        mmebane|             267|   1248.0|            1|\n",
      "|       1227|FlemishBeeCycle|             444|   1227.0|            1|\n",
      "|       1172|     hannahmitt|             136|   1172.0|            1|\n",
      "|       1125|  afraidofadria|             985|   1125.0|            1|\n",
      "|       4354|   patricktomas|             385|   1088.5|            4|\n",
      "+-----------+---------------+----------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is bias on YC\n",
    "sqlStatement = \"\"\"\n",
    "SELECT score, title,id\n",
    "FROM `story`\n",
    "WHERE title like \"%Y Combinator%\" or title like \"%YCombinator%\" or title like \"%ycombinator%\" or title like \"%y combinator%\"\n",
    "ORDER BY score  DESC\n",
    "\"\"\"\n",
    "YC_df = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------+\n",
      "|score|               title|      id|\n",
      "+-----+--------------------+--------+\n",
      "| 1065|Y Combinator is f...| 5059806|\n",
      "|  841|Y Combinator has ...| 8033322|\n",
      "|  705|Meet Watsi, Y Com...| 5117385|\n",
      "|  687|New: Apply to Y C...| 3700712|\n",
      "|  634|I Am Sam Altman, ...| 9238839|\n",
      "|  589|How I Got Kicked ...| 2208155|\n",
      "|  550|Benefits matter, ...| 5409273|\n",
      "|  549|What Happens At Y...| 1733236|\n",
      "|  542|How Y Combinator ...| 3711008|\n",
      "|  506|Y Combinator Numbers| 2608440|\n",
      "|  432|New Y Combinator ...| 7972138|\n",
      "|  425|Yuri Milner, SV A...| 2154706|\n",
      "|  380|Y Combinator And ...| 8178450|\n",
      "|  379|How I Crashed and...| 8867335|\n",
      "|  368|Early Photos of Y...| 2942958|\n",
      "|  366|Investment Firm Y...| 3492711|\n",
      "|  344|Y Combinator anno...| 1898432|\n",
      "|  342|Offer HN now at n...| 1840060|\n",
      "|  337|A note I sent to ...| 4273460|\n",
      "|  336|I am Sam Altman, ...|10360911|\n",
      "+-----+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "YC_df.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stories of major companies over the year\n",
    "# apple\n",
    "sqlStatement = \"\"\"\n",
    "SELECT count(*) as total_stories, SUM(score) as total_score,\n",
    "year(time_ts) as year\n",
    "FROM story\n",
    "WHERE title like \"%apple%\" or title like \"%APPLE\" or title like \"%Apple\"\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "\"\"\"\n",
    "Comp_df1 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----+\n",
      "|total_stories|total_score|year|\n",
      "+-------------+-----------+----+\n",
      "|            1|          7|2006|\n",
      "|           28|        109|2007|\n",
      "|           43|        324|2008|\n",
      "|           86|        780|2009|\n",
      "|          194|       1964|2010|\n",
      "|          348|       5316|2011|\n",
      "|          382|       4883|2012|\n",
      "|          280|       2345|2013|\n",
      "|          203|       2302|2014|\n",
      "|          168|       3672|2015|\n",
      "+-------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Comp_df1.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stories of major companies over the year\n",
    "# google\n",
    "sqlStatement = \"\"\"\n",
    "SELECT count(*) as total_stories, SUM(score) as total_score,\n",
    "year(time_ts) as year\n",
    "FROM story\n",
    "WHERE title like \"%google%\" or title like \"%GOOGLE\" or title like \"%Google\"\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "\"\"\"\n",
    "Comp_df2 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----+\n",
      "|total_stories|total_score|year|\n",
      "+-------------+-----------+----+\n",
      "|            1|          1|2006|\n",
      "|          102|        514|2007|\n",
      "|          190|       1192|2008|\n",
      "|          428|       3376|2009|\n",
      "|          553|       6938|2010|\n",
      "|          506|       9489|2011|\n",
      "|          461|       7592|2012|\n",
      "|          478|      10844|2013|\n",
      "|          432|       7835|2014|\n",
      "|          369|       9247|2015|\n",
      "+-------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Comp_df2.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stories of major companies over the year\n",
    "# uber\n",
    "sqlStatement = \"\"\"\n",
    "SELECT count(*) as total_stories, SUM(score) as total_score,\n",
    "year(time_ts) as year\n",
    "FROM story\n",
    "WHERE title like \"%uber%\" or title like \"%UBER\" or title like \"%Uber\"\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "\"\"\"\n",
    "Comp_df3 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----+\n",
      "|total_stories|total_score|year|\n",
      "+-------------+-----------+----+\n",
      "|            3|          3|2007|\n",
      "|           22|        202|2008|\n",
      "|           23|        957|2009|\n",
      "|           59|       1110|2010|\n",
      "|           69|        966|2011|\n",
      "|           58|        874|2012|\n",
      "|           67|        523|2013|\n",
      "|          244|       2743|2014|\n",
      "|          302|       3301|2015|\n",
      "+-------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Comp_df3.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset comments\n",
    "data_df2 = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://chingsez/Final/comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+------+----------+--------------------+--------------------+--------------------+--------------------+-------+-------+\n",
      "|                  id|     by|author|      time|             time_ts|                text|              parent|             deleted|   dead|ranking|\n",
      "+--------------------+-------+------+----------+--------------------+--------------------+--------------------+--------------------+-------+-------+\n",
      "|             2701393|     5l|    5l|1309184881|2011-06-27 14:28:...|And the glazier w...|             2701243|                null|   null|      0|\n",
      "|             5811403|     99|    99|1370234048|2013-06-03 04:34:...|Does canada have ...|             5804452|                null|   null|      0|\n",
      "|               21623|     AF|    AF|1178992400|2007-05-12 17:53:...|\"Speaking of Rail...|               21611|                null|   null|      0|\n",
      "|            10159727|     EA|    EA|1441206574|2015-09-02 15:09:...|Humans and large ...|            10159396|                null|   null|      0|\n",
      "|             2988424|     Iv|    Iv|1315853580|2011-09-12 18:53:...|I must say I reac...|             2988179|                null|   null|      0|\n",
      "|             3867418|     Iv|    Iv|1334921984|2012-04-20 11:39:...|&#62; There's a w...|             3867404|                null|   null|      0|\n",
      "|             3925617|     Iv|    Iv|1336076765|2012-05-03 20:26:...|I'm also in this ...|             3924840|                null|   null|      0|\n",
      "|             3107534|     Iv|    Iv|1318520044|2011-10-13 15:34:...|how do you run un...|                null|                null|   null|   null|\n",
      "|It has always ref...|3107241|  null|      null|                   0|                null|                null|                null|   null|   null|\n",
      "|             8409259|     Iv|    Iv|1412421647|2014-10-04 11:20:...|Polio is not exte...|             8409226|                null|   null|      0|\n",
      "|             2855741|     Jd|    Jd|1312690646|2011-08-07 04:17:...|\"Yep, I didn't fi...| but nothing that...| it may not be th...|2855343|   null|\n",
      "|               50570|     Jd|    Jd|1189011845|2007-09-05 17:04:...|It was a risky jo...|               50556|                null|   null|      0|\n",
      "|             2600618|     Jd|    Jd|1306794854|2011-05-30 22:34:...|\"Looks good, ther...|             2600609|                null|   null|      0|\n",
      "|             2600423|     Jd|    Jd|1306789205|2011-05-30 21:00:...|A bit, but so muc...|             2599323|                null|   null|      0|\n",
      "|             1983932|     Jd|    Jd|1291831945|2010-12-08 18:12:...|I also agree with...|             1979965|                null|   null|      0|\n",
      "|             5824036|     Jd|    Jd|1370414140|2013-06-05 06:35:...|Sadly doesn't pro...|             5824021|                null|   null|      0|\n",
      "|               73111|     Jd|    Jd|1193467001|2007-10-27 06:36:...|Feferman usefully...|               73107|                null|   null|      0|\n",
      "|             4569290|     Jd|    Jd|1348562302|2012-09-25 08:38:...|\"Here are my take...|             4569255|                null|   null|      0|\n",
      "|              319968|     KB|    KB|1222805047|2008-09-30 20:04:...|\"You may find a f...|              319943|                null|   null|      0|\n",
      "|             9699296|     M8|    M8|1434026580|2015-06-11 12:43:...|       For instance?|             9698927|                null|   null|      0|\n",
      "+--------------------+-------+------+----------+--------------------+--------------------+--------------------+--------------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- by: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- time_ts: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- parent: string (nullable = true)\n",
      " |-- deleted: string (nullable = true)\n",
      " |-- dead: string (nullable = true)\n",
      " |-- ranking: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9796725"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "comment_df = data_df2.select(\n",
    "                     data_df2['id'].cast(IntegerType()),                    \n",
    "                     data_df2['time_ts'].cast('timestamp'),                  \n",
    "                     data_df2['text'],\n",
    "                     data_df2['parent'].cast(IntegerType()),\n",
    "                     #data_df2['deleted'],\n",
    "                     #data_df2['dead'],\n",
    "                     data_df2['author'],\n",
    "                     data_df2['ranking'].cast(IntegerType())\n",
    "\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- time_ts: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- parent: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- ranking: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------------------+--------+------+-------+\n",
      "|      id|            time_ts|                text|  parent|author|ranking|\n",
      "+--------+-------------------+--------------------+--------+------+-------+\n",
      "| 2701393|2011-06-27 14:28:01|And the glazier w...| 2701243|    5l|      0|\n",
      "| 5811403|2013-06-03 04:34:08|Does canada have ...| 5804452|    99|      0|\n",
      "|   21623|2007-05-12 17:53:20|\"Speaking of Rail...|   21611|    AF|      0|\n",
      "|10159727|2015-09-02 15:09:34|Humans and large ...|10159396|    EA|      0|\n",
      "| 2988424|2011-09-12 18:53:00|I must say I reac...| 2988179|    Iv|      0|\n",
      "| 3867418|2012-04-20 11:39:44|&#62; There's a w...| 3867404|    Iv|      0|\n",
      "| 3925617|2012-05-03 20:26:05|I'm also in this ...| 3924840|    Iv|      0|\n",
      "| 3107534|2011-10-13 15:34:04|how do you run un...|    null|    Iv|   null|\n",
      "|    null|               null|                null|    null|  null|   null|\n",
      "| 8409259|2014-10-04 11:20:47|Polio is not exte...| 8409226|    Iv|      0|\n",
      "+--------+-------------------+--------------------+--------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df.createOrReplaceTempView('ini_comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8399564"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_df.select(\"id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comment_df = spark.sql('select * from ini_comment where id is not NULL and time_ts is not NULL and text is not NULL and author is not NULL and ranking is not NULL')\n",
    "clean_comment_df.createOrReplaceTempView('comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6986995"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comment_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------------------+--------+------+-------+\n",
      "|      id|            time_ts|                text|  parent|author|ranking|\n",
      "+--------+-------------------+--------------------+--------+------+-------+\n",
      "| 2701393|2011-06-27 14:28:01|And the glazier w...| 2701243|    5l|      0|\n",
      "| 5811403|2013-06-03 04:34:08|Does canada have ...| 5804452|    99|      0|\n",
      "|   21623|2007-05-12 17:53:20|\"Speaking of Rail...|   21611|    AF|      0|\n",
      "|10159727|2015-09-02 15:09:34|Humans and large ...|10159396|    EA|      0|\n",
      "| 2988424|2011-09-12 18:53:00|I must say I reac...| 2988179|    Iv|      0|\n",
      "| 3867418|2012-04-20 11:39:44|&#62; There's a w...| 3867404|    Iv|      0|\n",
      "| 3925617|2012-05-03 20:26:05|I'm also in this ...| 3924840|    Iv|      0|\n",
      "| 8409259|2014-10-04 11:20:47|Polio is not exte...| 8409226|    Iv|      0|\n",
      "|   50570|2007-09-05 17:04:05|It was a risky jo...|   50556|    Jd|      0|\n",
      "| 2600618|2011-05-30 22:34:14|\"Looks good, ther...| 2600609|    Jd|      0|\n",
      "+--------+-------------------+--------------------+--------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_comment_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment author/user information \n",
    "# who are the most contributive authors in Hacker News ?\n",
    "## futhur to be done——can be joined with the most contirbutive authors in story\n",
    "\n",
    "sqlStatement = \"\"\"SELECT author,\n",
    "        COUNT(id) AS total_comments\n",
    "        From comment\n",
    "        GROUP BY author\n",
    "        ORDER BY total_comments DESC\n",
    "        LIMIT 20\n",
    "\"\"\"\n",
    "comment_user_df = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|      author|total_comments|\n",
      "+------------+--------------+\n",
      "|     tptacek|         28605|\n",
      "|    jacquesm|         19845|\n",
      "|       DanBC|         10992|\n",
      "|    jrockway|         10679|\n",
      "|   anigbrowl|         10490|\n",
      "|dragonwriter|         10203|\n",
      "|         eru|          9979|\n",
      "|     rbanffy|          9634|\n",
      "|       sp332|          9547|\n",
      "|     rayiner|          9403|\n",
      "+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 10\n",
    "comment_user_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment distribution in terms of time\n",
    "# What is the trend of comment numbers from 2006-2016 in Hacker News?\n",
    "\n",
    "sqlStatement = \"\"\"\n",
    "SELECT COUNT(id) AS comment_num, \n",
    "year(time_ts) as year\n",
    "FROM comment\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "\"\"\"\n",
    "comment_time_df2 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n",
      "|comment_num|year|\n",
      "+-----------+----+\n",
      "|         10|2006|\n",
      "|      50982|2007|\n",
      "|     195678|2008|\n",
      "|     382490|2009|\n",
      "|     658846|2010|\n",
      "|     816999|2011|\n",
      "|     975306|2012|\n",
      "|    1415381|2013|\n",
      "|    1348324|2014|\n",
      "|    1142979|2015|\n",
      "+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment_time_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment distribution in terms of time\n",
    "# What is the most popular/active time during a day in pubulishing a comment?\n",
    "\n",
    "sqlStatement = \"\"\"\n",
    "SELECT COUNT(id) AS comment_num, \n",
    "hour(time_ts) as hour\n",
    "FROM comment\n",
    "GROUP BY hour\n",
    "ORDER BY comment_num DESC\n",
    "\"\"\"\n",
    "comment_time_df = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n",
      "|comment_num|hour|\n",
      "+-----------+----+\n",
      "|     451259|  17|\n",
      "|     450094|  18|\n",
      "|     437369|  16|\n",
      "|     433640|  19|\n",
      "|     421504|  20|\n",
      "|     413518|  15|\n",
      "|     398429|  21|\n",
      "|     365798|  14|\n",
      "|     353708|  22|\n",
      "|     313262|  23|\n",
      "|     295136|  13|\n",
      "|     276703|   0|\n",
      "|     251256|   1|\n",
      "|     236036|   2|\n",
      "|     224956|   3|\n",
      "|     224367|  12|\n",
      "|     210740|   4|\n",
      "|     192913|   5|\n",
      "|     180795|   6|\n",
      "|     180141|  11|\n",
      "|     172147|   7|\n",
      "|     170884|   8|\n",
      "|     168104|   9|\n",
      "|     164236|  10|\n",
      "+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment_time_df.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top(the hottest) comments with the most follow-up comment \n",
    "sqlStatement = \"\"\"\n",
    "SELECT COUNT(id) AS followup_num, \n",
    "parent\n",
    "FROM comment\n",
    "WHERE parent is not NULL\n",
    "GROUP BY parent\n",
    "ORDER BY followup_num DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "comment_parent_df1 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|followup_num|  parent|\n",
      "+------------+--------+\n",
      "|         975|     363|\n",
      "|         266| 7469115|\n",
      "|         266| 9996333|\n",
      "|         264| 9238839|\n",
      "|         262| 9812245|\n",
      "|         243| 7445761|\n",
      "|         241|10152809|\n",
      "|         239|  752262|\n",
      "|         234| 9471287|\n",
      "|         228| 9303396|\n",
      "+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 10\n",
    "comment_parent_df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(ranking)=-1051, max(ranking)=1131019295, avg(ranking)=58481.1891668736)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ranking information\n",
    "# what is the average ranking of those comments?\n",
    "\n",
    "spark.sql(\"select min(ranking),max(ranking),avg(ranking) from comment\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author/user's ranking information decending by avg ranking \n",
    "# who has the highest avg ranking?\n",
    "\n",
    "sqlStatement = \"\"\"SELECT avg(ranking) as avg_ranking,author,\n",
    "count(id) as total_comment\n",
    "FROM comment\n",
    "GROUP BY author\n",
    "ORDER BY avg(ranking) DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "comment_user_df1 = spark.sql(sqlStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------+\n",
      "|         avg_ranking|      author|total_comment|\n",
      "+--------------------+------------+-------------+\n",
      "|         2.0630034E7|AretNCarlsen|           56|\n",
      "|1.5151532969696969E7|     dedalus|           66|\n",
      "|         1.0360911E7|      pratim|            1|\n",
      "|         1.0359641E7|    vmuhonen|            1|\n",
      "|           1.03454E7|   scopesoft|            1|\n",
      "|         1.0288613E7|  FlexMonkey|            1|\n",
      "|         1.0277638E7|   Jimbobian|            1|\n",
      "|         1.0275866E7| waynebeaton|            1|\n",
      "|         1.0250132E7| anonttttttt|            1|\n",
      "|         1.0230206E7|      bduhan|            1|\n",
      "+--------------------+------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 10\n",
    "comment_user_df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comment_df.createOrReplaceTempView('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.sql('select * from tmp limit 200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------------------+--------+---------------+-------+\n",
      "|      id|            time_ts|                text|  parent|         author|ranking|\n",
      "+--------+-------------------+--------------------+--------+---------------+-------+\n",
      "|  803232|2009-09-03 19:09:48|I've been coding ...|  802700|    heckacopter|      5|\n",
      "| 8147414|2014-08-07 12:53:18|I think of Snowde...| 8146987|    justnotsure|      5|\n",
      "|10331827|2015-10-05 13:59:13|Actually has led ...|10331623|    littletimmy|      5|\n",
      "| 3058176|2011-09-30 19:04:37|Interesting siden...| 3054310|    underdesign|      5|\n",
      "| 2582615|2011-05-25 02:27:49|Silly geeks.  A w...| 2582002|   originalgeek|      5|\n",
      "| 9335083|2015-04-07 16:19:46|This.  I also lik...| 9331453|   pauldirac137|      5|\n",
      "| 7349363|2014-03-05 19:48:55|These are just #h...| 7332992|  hipsterduuche|      5|\n",
      "| 2769120|2011-07-15 21:11:01|Time to kiss Arri...| 2769046|  immortalbeast|      5|\n",
      "| 6867776|2013-12-07 21:32:36|my classmate&#x27...| 6867543|  whitneyrblack|      5|\n",
      "| 6345460|2013-09-07 16:21:45|\"I&#x27;m making ...| 6345413| SamanthaGray44|      5|\n",
      "|  962627|2009-11-26 13:32:54|I'm a fan of appl...|  962598| haydenchambers|      5|\n",
      "| 5991345|2013-07-04 16:28:52|It feels good, bu...| 5991081| stefan_kendall|      5|\n",
      "| 4775498|2012-11-13 00:12:53|               Yawn.| 4772786|LilValleyBigEgo|      5|\n",
      "|  843464|2009-09-25 14:00:42|Yet another right...|  843304|The_Lost_Hacker|      5|\n",
      "| 9597616|2015-05-24 21:09:05|Good question. Na...| 9597522|sebastianconcpt|      5|\n",
      "| 4286649|2012-07-24 17:09:59|\"nice. you just p...| 4286566|            gcb|      6|\n",
      "| 5931804|2013-06-24 09:02:29|Impressed with th...| 5931409|           GGev|      6|\n",
      "|  283695|2008-08-22 14:13:33|This thread sure ...|  282234|           jazj|      6|\n",
      "| 2687215|2011-06-23 09:04:57|So women are good...| 2684549|          robak|      6|\n",
      "| 2525797|2011-05-08 12:57:46|I am looking for ...| 2522466|         giants|      6|\n",
      "+--------+-------------------+--------------------+--------+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.withColumn(\"split\", split(\"text\", \"\\s+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------------------+--------+------+-------+--------------------+\n",
      "|      id|            time_ts|                text|  parent|author|ranking|               split|\n",
      "+--------+-------------------+--------------------+--------+------+-------+--------------------+\n",
      "| 2701393|2011-06-27 14:28:01|And the glazier w...| 2701243|    5l|      0|[And, the, glazie...|\n",
      "| 5811403|2013-06-03 04:34:08|Does canada have ...| 5804452|    99|      0|[Does, canada, ha...|\n",
      "|   21623|2007-05-12 17:53:20|\"Speaking of Rail...|   21611|    AF|      0|[\"Speaking, of, R...|\n",
      "|10159727|2015-09-02 15:09:34|Humans and large ...|10159396|    EA|      0|[Humans, and, lar...|\n",
      "| 2988424|2011-09-12 18:53:00|I must say I reac...| 2988179|    Iv|      0|[I, must, say, I,...|\n",
      "| 3867418|2012-04-20 11:39:44|&#62; There's a w...| 3867404|    Iv|      0|[&#62;, There's, ...|\n",
      "| 3925617|2012-05-03 20:26:05|I'm also in this ...| 3924840|    Iv|      0|[I'm, also, in, t...|\n",
      "| 8409259|2014-10-04 11:20:47|Polio is not exte...| 8409226|    Iv|      0|[Polio, is, not, ...|\n",
      "|   50570|2007-09-05 17:04:05|It was a risky jo...|   50556|    Jd|      0|[It, was, a, risk...|\n",
      "| 2600618|2011-05-30 22:34:14|\"Looks good, ther...| 2600609|    Jd|      0|[\"Looks, good,, t...|\n",
      "| 2600423|2011-05-30 21:00:05|A bit, but so muc...| 2599323|    Jd|      0|[A, bit,, but, so...|\n",
      "| 1983932|2010-12-08 18:12:25|I also agree with...| 1979965|    Jd|      0|[I, also, agree, ...|\n",
      "| 5824036|2013-06-05 06:35:40|Sadly doesn't pro...| 5824021|    Jd|      0|[Sadly, doesn't, ...|\n",
      "|   73111|2007-10-27 06:36:41|Feferman usefully...|   73107|    Jd|      0|[Feferman, useful...|\n",
      "| 4569290|2012-09-25 08:38:22|\"Here are my take...| 4569255|    Jd|      0|[\"Here, are, my, ...|\n",
      "|  319968|2008-09-30 20:04:07|\"You may find a f...|  319943|    KB|      0|[\"You, may, find,...|\n",
      "| 9699296|2015-06-11 12:43:00|       For instance?| 9698927|    M8|      0|    [For, instance?]|\n",
      "| 4895850|2012-12-09 19:55:35|So, basically, yo...| 4895812|    Mz|      0|[So,, basically,,...|\n",
      "|10313701|2015-10-01 18:56:55|One way to test y...|10313194|    Mz|      0|[One, way, to, te...|\n",
      "| 4911653|2012-12-12 18:27:15|\"Maybe you should...|    null|    Mz|4911595|[\"Maybe, you, sho...|\n",
      "+--------+-------------------+--------------------+--------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |tokens|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|minimalists don't use macs bud                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |[minimalists, don't, use, macs, bud]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |5     |\n",
      "|What if the writer's other activities involved sucking the brains out of baby skulls?<p>Of course association matters, though this particular instance is of course debatable.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |[what, if, the, writer's, other, activities, involved, sucking, the, brains, out, of, baby, skulls?<p>of, course, association, matters,, though, this, particular, instance, is, of, course, debatable.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |25    |\n",
      "|you've missed the point of the gold standard entirely.<p>people don't advocate gold because they like shiny things. people advocate gold because it is a generally accepted numismatic metal for which the supply is finite and dependable, and there is a long history of validating and assaying gold as a measure of trade. you could just as easily substitute any other metal or <i>fixed-quantity</i> commodity like wheat or corn (although cocoa puffs are a product of manufacture so they would make a poor choice).<p>the point is that the securing asset not be something that can be created at will, as in the case of a fiat currency.<p>all fiat currencies have failed given enough time. gold has yet to fail once at being a decent store of value over 3k years.                        |[you've, missed, the, point, of, the, gold, standard, entirely.<p>people, don't, advocate, gold, because, they, like, shiny, things., people, advocate, gold, because, it, is, a, generally, accepted, numismatic, metal, for, which, the, supply, is, finite, and, dependable,, and, there, is, a, long, history, of, validating, and, assaying, gold, as, a, measure, of, trade., you, could, just, as, easily, substitute, any, other, metal, or, <i>fixed-quantity</i>, commodity, like, wheat, or, corn, (although, cocoa, puffs, are, a, product, of, manufacture, so, they, would, make, a, poor, choice).<p>the, point, is, that, the, securing, asset, not, be, something, that, can, be, created, at, will,, as, in, the, case, of, a, fiat, currency.<p>all, fiat, currencies, have, failed, given, enough, time., gold, has, yet, to, fail, once, at, being, a, decent, store, of, value, over, 3k, years.]              |129   |\n",
      "|I, however, would make the bet that they never ever are used again.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |[i,, however,, would, make, the, bet, that, they, never, ever, are, used, again.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |13    |\n",
      "|Thanks for this. You just made my day! :D                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[thanks, for, this., you, just, made, my, day!, :d]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |9     |\n",
      "|&gt; You&#x27;re way off base. Commenting on a colleague&#x27;s personal appearance to other colleagues is totally inappropriate. Commenting on a colleague&#x27;s appearance in a bathing suit is totally inappropriate.<p>I disagree<p>&gt; If you think these remarks are appropriate and non-sexual then you should probably just keep your mouth shut.<p>If you&#x27;re referring to the &quot;You look amazing in that bathing suit, like a rock star&quot;, um, no, I don&#x27;t consider that inappropriate at all. I&#x27;m not going to keep my mouth shut, thanks. If your goal is to intimidate others who disagree with you into silence rather than have a real discussion, then you don&#x27;t really belong on HN. I&#x27;m sure there are subreddits on Reddit.com that cater to your needs.|[&gt;, you&#x27;re, way, off, base., commenting, on, a, colleague&#x27;s, personal, appearance, to, other, colleagues, is, totally, inappropriate., commenting, on, a, colleague&#x27;s, appearance, in, a, bathing, suit, is, totally, inappropriate.<p>i, disagree<p>&gt;, if, you, think, these, remarks, are, appropriate, and, non-sexual, then, you, should, probably, just, keep, your, mouth, shut.<p>if, you&#x27;re, referring, to, the, &quot;you, look, amazing, in, that, bathing, suit,, like, a, rock, star&quot;,, um,, no,, i, don&#x27;t, consider, that, inappropriate, at, all., i&#x27;m, not, going, to, keep, my, mouth, shut,, thanks., if, your, goal, is, to, intimidate, others, who, disagree, with, you, into, silence, rather, than, have, a, real, discussion,, then, you, don&#x27;t, really, belong, on, hn., i&#x27;m, sure, there, are, subreddits, on, reddit.com, that, cater, to, your, needs.]|119   |\n",
      "|Ps. If you ever see yourselve in the same situation... My friend would never proposed it on his own... He didnt want to impact the group, but he will appreciate it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |[ps., if, you, ever, see, yourselve, in, the, same, situation..., my, friend, would, never, proposed, it, on, his, own..., he, didnt, want, to, impact, the, group,, but, he, will, appreciate, it.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |31    |\n",
      "|OK, going from analogy back to reality, how do you return a copy of software?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |[ok,, going, from, analogy, back, to, reality,, how, do, you, return, a, copy, of, software?]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |15    |\n",
      "|What are your living expenses, though. It&#x27;s not top-line salary that matters, if you have to piss it away on renting a one-bedroom apt...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |[what, are, your, living, expenses,, though., it&#x27;s, not, top-line, salary, that, matters,, if, you, have, to, piss, it, away, on, renting, a, one-bedroom, apt...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |24    |\n",
      "|In addition, C++ has a whole pile of other problems too.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |[in, addition,, c++, has, a, whole, pile, of, other, problems, too.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |11    |\n",
      "|OK, I laughed out loud at the last one.<p>Its true how that word has lost its meaning. Don't mean to pick on the article from the OP though, he seems like a nice enough guy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |[ok,, i, laughed, out, loud, at, the, last, one.<p>its, true, how, that, word, has, lost, its, meaning., don't, mean, to, pick, on, the, article, from, the, op, though,, he, seems, like, a, nice, enough, guy.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |35    |\n",
      "|\"&#62;And after several products from several manufacturers have proven the change to focused-single-task to be not only palatable, but even preferable and popular.<p>And these devices have all had relatively small displays with totally different input methods, which is my entire point. It's the same mistake that was made in the early days of mobile devices in reverse. I don't believe that interface paradigms are one-size-fits-all. Totally modal interfaces ala iPhone/iPad make sense when you have to maximize display efficiency, but they don't make anywhere near as much sense when you have 20\"\"+ displays with megapixel level resolutions to work with.\"                                                                                                                           |[\"&#62;and, after, several, products, from, several, manufacturers, have, proven, the, change, to, focused-single-task, to, be, not, only, palatable,, but, even, preferable, and, popular.<p>and, these, devices, have, all, had, relatively, small, displays, with, totally, different, input, methods,, which, is, my, entire, point., it's, the, same, mistake, that, was, made, in, the, early, days, of, mobile, devices, in, reverse., i, don't, believe, that, interface, paradigms, are, one-size-fits-all., totally, modal, interfaces, ala, iphone/ipad, make, sense, when, you, have, to, maximize, display, efficiency,, but, they, don't, make, anywhere, near, as, much, sense, when, you, have, 20\"\"+, displays, with, megapixel, level, resolutions, to, work, with.\"]                                                                                                                                              |100   |\n",
      "|Exactly!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[exactly!!]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |1     |\n",
      "|download                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |[download]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |1     |\n",
      "|Dallas has the largest light rail system in the United States. It's been around since 1996.<p>DFW access is planned for 2014.<p>Public transport in Texas is fucked.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |[dallas, has, the, largest, light, rail, system, in, the, united, states., it's, been, around, since, 1996.<p>dfw, access, is, planned, for, 2014.<p>public, transport, in, texas, is, fucked.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |26    |\n",
      "|Gnosis as in Samael Aun Weor?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |[gnosis, as, in, samael, aun, weor?]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |6     |\n",
      "|I don&#x27;t see why their mobile page should be different when iOS 8 is reelased. It&#x27;s the same problem I have with their desktop site actually. The quick answer box at the top of search results that thinks it knows what I want takes up way too much space.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |[i, don&#x27;t, see, why, their, mobile, page, should, be, different, when, ios, 8, is, reelased., it&#x27;s, the, same, problem, i, have, with, their, desktop, site, actually., the, quick, answer, box, at, the, top, of, search, results, that, thinks, it, knows, what, i, want, takes, up, way, too, much, space.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |49    |\n",
      "|I wanna call shenanigans _because_ it goes to paypal ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |[i, wanna, call, shenanigans, _because_, it, goes, to, paypal, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |10    |\n",
      "|&#x27;They are so tunnel vision that they just refuse to acknowledge what a 90% failure rate means.&#x27;<p>yes it means 1 out of 10 becomes fabulously wealthy and semi-famous...those are pretty great odds as compared as going to work for someone else.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |[&#x27;they, are, so, tunnel, vision, that, they, just, refuse, to, acknowledge, what, a, 90%, failure, rate, means.&#x27;<p>yes, it, means, 1, out, of, 10, becomes, fabulously, wealthy, and, semi-famous...those, are, pretty, great, odds, as, compared, as, going, to, work, for, someone, else.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |41    |\n",
      "|&#62; This is why dieting must always be paired with exercise.<p>No it mustn't.  A lot of people have difficulty with the increased appetite that ensues.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[&#62;, this, is, why, dieting, must, always, be, paired, with, exercise.<p>no, it, mustn't., , a, lot, of, people, have, difficulty, with, the, increased, appetite, that, ensues.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |26    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tokenized = tokenizer.transform(test)\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "tokenized.select(\"text\", \"words\")\\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|               words|\n",
      "+--------------------+--------------------+\n",
      "|My computing expe...|[my, computing, e...|\n",
      "|Does anybody know...|[does, anybody, k...|\n",
      "|Macbook Air (Or a...|[macbook, air, (o...|\n",
      "|   awesome upgrade..|[awesome, upgrade..]|\n",
      "|      Atlas Shrugged|   [atlas, shrugged]|\n",
      "|Has anyone here m...|[has, anyone, her...|\n",
      "|I'm eagerly waiti...|[i'm, eagerly, wa...|\n",
      "|I always got jobs...|[i, always, got, ...|\n",
      "|Trello and Everno...|[trello, and, eve...|\n",
      "|I was waiting for...|[i, was, waiting,...|\n",
      "|Microsoft is in t...|[microsoft, is, i...|\n",
      "|He's out there so...|[he's, out, there...|\n",
      "|I had the same fe...|[i, had, the, sam...|\n",
      "|\"Found this one v...|[\"found, this, on...|\n",
      "|Wow. I didn't thi...|[wow., i, didn't,...|\n",
      "|Just remember tha...|[just, remember, ...|\n",
      "|I don't understan...|[i, don't, unders...|\n",
      "|Looks like Spiege...|[looks, like, spi...|\n",
      "|Sounds like a mas...|[sounds, like, a,...|\n",
      "|Good idea but I h...|[good, idea, but,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\s+\")\n",
    "regexTokenized = regexTokenizer.transform(test)\n",
    "regexTokenized.select(\"text\", \"words\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+-------+---------+-------+--------------------+\n",
      "|     id|            time_ts|                text| parent|   author|ranking|               words|\n",
      "+-------+-------------------+--------------------+-------+---------+-------+--------------------+\n",
      "|1876849|2010-11-06 13:39:56|minimalists don't...|1876724| thedeuce|      1|[minimalists, don...|\n",
      "|1194782|2010-03-16 02:41:25|What if the write...|1194331| tphyahoo|      1|[what, if, the, w...|\n",
      "| 415216|2008-12-31 06:32:21|you've missed the...| 415156| unrealwh|      1|[you've, missed, ...|\n",
      "|8180803|2014-08-15 02:30:39|I, however, would...|8179627|Chronic29|      1|[i,, however,, wo...|\n",
      "|5736766|2013-05-20 09:49:59|Thanks for this. ...|5736640|Gallefray|      1|[thanks, for, thi...|\n",
      "+-------+-------------------+--------------------+-------+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = remover.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered2 = remover.transform(regexTokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------------------+--------+---------------+-------+--------------------+--------------------+\n",
      "|      id|            time_ts|                text|  parent|         author|ranking|               words|            filtered|\n",
      "+--------+-------------------+--------------------+--------+---------------+-------+--------------------+--------------------+\n",
      "|  803232|2009-09-03 19:09:48|I've been coding ...|  802700|    heckacopter|      5|[i've, been, codi...|[coding, almost, ...|\n",
      "| 8147414|2014-08-07 12:53:18|I think of Snowde...| 8146987|    justnotsure|      5|[i, think, of, sn...|[think, snowden, ...|\n",
      "|10331827|2015-10-05 13:59:13|Actually has led ...|10331623|    littletimmy|      5|[actually, has, l...|[actually, led, s...|\n",
      "| 3058176|2011-09-30 19:04:37|Interesting siden...| 3054310|    underdesign|      5|[interesting, sid...|[interesting, sid...|\n",
      "| 2582615|2011-05-25 02:27:49|Silly geeks.  A w...| 2582002|   originalgeek|      5|[silly, geeks., ,...|[silly, geeks., ,...|\n",
      "| 9335083|2015-04-07 16:19:46|This.  I also lik...| 9331453|   pauldirac137|      5|[this., , i, also...|[this., , also, l...|\n",
      "| 7349363|2014-03-05 19:48:55|These are just #h...| 7332992|  hipsterduuche|      5|[these, are, just...|[#hipster, coding...|\n",
      "| 2769120|2011-07-15 21:11:01|Time to kiss Arri...| 2769046|  immortalbeast|      5|[time, to, kiss, ...|[time, kiss, arri...|\n",
      "| 6867776|2013-12-07 21:32:36|my classmate&#x27...| 6867543|  whitneyrblack|      5|[my, classmate&#x...|[classmate&#x27;s...|\n",
      "| 6345460|2013-09-07 16:21:45|\"I&#x27;m making ...| 6345413| SamanthaGray44|      5|[\"i&#x27;m, makin...|[\"i&#x27;m, makin...|\n",
      "|  962627|2009-11-26 13:32:54|I'm a fan of appl...|  962598| haydenchambers|      5|[i'm, a, fan, of,...|[fan, apple, (no,...|\n",
      "| 5991345|2013-07-04 16:28:52|It feels good, bu...| 5991081| stefan_kendall|      5|[it, feels, good,...|[feels, good,, yo...|\n",
      "| 4775498|2012-11-13 00:12:53|               Yawn.| 4772786|LilValleyBigEgo|      5|             [yawn.]|             [yawn.]|\n",
      "|  843464|2009-09-25 14:00:42|Yet another right...|  843304|The_Lost_Hacker|      5|[yet, another, ri...|[yet, another, ri...|\n",
      "| 9597616|2015-05-24 21:09:05|Good question. Na...| 9597522|sebastianconcpt|      5|[good, question.,...|[good, question.,...|\n",
      "| 4286649|2012-07-24 17:09:59|\"nice. you just p...| 4286566|            gcb|      6|[\"nice., you, jus...|[\"nice., proved, ...|\n",
      "| 5931804|2013-06-24 09:02:29|Impressed with th...| 5931409|           GGev|      6|[impressed, with,...|[impressed, demo,...|\n",
      "|  283695|2008-08-22 14:13:33|This thread sure ...|  282234|           jazj|      6|[this, thread, su...|[thread, sure, go...|\n",
      "| 2687215|2011-06-23 09:04:57|So women are good...| 2684549|          robak|      6|[so, women, are, ...|[women, good, typ...|\n",
      "| 2525797|2011-05-08 12:57:46|I am looking for ...| 2522466|         giants|      6|[i, am, looking, ...|[looking, someone...|\n",
      "+--------+-------------------+--------------------+--------+---------------+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     word|count|\n",
      "+---------+-----+\n",
      "|         |  119|\n",
      "|   people|   50|\n",
      "|     like|   40|\n",
      "|    think|   30|\n",
      "|      one|   25|\n",
      "|     much|   24|\n",
      "|      way|   24|\n",
      "|     make|   23|\n",
      "|      get|   23|\n",
      "|   really|   22|\n",
      "|      use|   19|\n",
      "|something|   19|\n",
      "|     good|   17|\n",
      "|     know|   17|\n",
      "|     also|   17|\n",
      "|   things|   17|\n",
      "|     need|   16|\n",
      "|   better|   16|\n",
      "|     even|   16|\n",
      "|     want|   15|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_count = filtered.withColumn('word', f.explode(f.col('filtered')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     word|count|\n",
      "+---------+-----+\n",
      "|   people|   50|\n",
      "|     like|   40|\n",
      "|    think|   30|\n",
      "|      one|   25|\n",
      "|      way|   24|\n",
      "|     much|   24|\n",
      "|      get|   23|\n",
      "|     make|   23|\n",
      "|   really|   22|\n",
      "|something|   19|\n",
      "|      use|   19|\n",
      "|     good|   17|\n",
      "|     know|   17|\n",
      "|   things|   17|\n",
      "|     also|   17|\n",
      "|     even|   16|\n",
      "|     need|   16|\n",
      "|   better|   16|\n",
      "|     want|   15|\n",
      "|   pretty|   15|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_count2 = filtered2.withColumn('word', f.explode(f.col('filtered')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面是真的可能没啥用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\") \n",
    "wordsData = tokenizer.transform(test)\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(features=SparseVector(20, {0: 0.4281, 2: 1.4164, 7: 1.3178, 8: 1.0005, 10: 0.8186, 12: 0.5759, 13: 0.4055, 15: 0.6028, 17: 0.4911, 18: 0.5075}), id=2701393)\n",
      "Row(features=SparseVector(20, {1: 0.4993, 3: 1.015, 4: 1.1518, 5: 0.475, 6: 0.6399, 7: 0.6589, 8: 0.667, 10: 0.5457, 11: 0.6783, 14: 0.5671, 16: 0.4435, 18: 0.5075, 19: 0.5326}), id=5811403)\n",
      "Row(features=SparseVector(20, {0: 1.7124, 1: 2.9957, 2: 0.7082, 3: 2.0301, 4: 3.4555, 5: 7.5999, 6: 3.1993, 7: 3.2946, 8: 4.0019, 9: 1.0652, 10: 3.2744, 11: 4.07, 12: 1.7278, 13: 2.0273, 14: 3.4026, 15: 2.4113, 16: 2.2175, 17: 1.4734, 18: 2.5376, 19: 1.5979}), id=21623)\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")  \n",
    "idfModel = idf.fit(featurizedData)  \n",
    "rescaledData = idfModel.transform(featurizedData)  \n",
    "for features_label in rescaledData.select(\"features\", \"id\").take(3):  \n",
    "    print(features_label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正则\n",
    "# split\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
