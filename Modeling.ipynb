{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"modeling\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.ml.regression as rg\n",
    "import pyspark.ml.clustering as clust\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, FloatType, DoubleType, StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import RFormula\n",
    "from sklearn.metrics import roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "data = spark.read\\\n",
    ".option('header', 'true')\\\n",
    ".option('inferSchema', 'true')\\\n",
    ".parquet('s3://chingsez/Final/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- score: integer (nullable = true)\n",
      " |-- descendants: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofweek: integer (nullable = true)\n",
      " |-- active_user: string (nullable = true)\n",
      " |-- title_length: integer (nullable = true)\n",
      " |-- from_top_web: string (nullable = true)\n",
      " |-- text_length: integer (nullable = true)\n",
      " |-- title_hot_words: integer (nullable = true)\n",
      " |-- title_array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title_vec: vector (nullable = true)\n",
      " |-- if_highscore: integer (nullable = true)\n",
      " |-- score_scaled: double (nullable = true)\n",
      " |-- if_highscore_scaled: integer (nullable = true)\n",
      " |-- des_scaled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data type\n",
    "convert = udf(lambda x: float(np.max(x)), FloatType())\n",
    "change = data.withColumn('active_user', f.col('active_user').cast('double'))\n",
    "change = change.withColumn('from_top_web', f.col('from_top_web').cast('double'))\n",
    "change = change.withColumn('title_vec', convert(\"title_vec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a correlation matrix for numerical variables\n",
    "cols = ['score', 'descendants', 'year', 'dayofweek', 'month', 'text_length', 'title_hot_words', 'title_vec', 'active_user', 'from_top_web']\n",
    "assemble = VectorAssembler(inputCols=cols,\n",
    "                           outputCol='feat')\n",
    "#Normailize features\n",
    "norm = StandardScaler(\n",
    "    inputCol= 'feat'\n",
    "    , outputCol='normed'\n",
    "    , withMean=True\n",
    "    , withStd=True\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        assemble\n",
    "        , norm\n",
    "    ])\n",
    "\n",
    "vector = pipeline.fit(change).transform(change).select('normed')\n",
    "matrix = Correlation.corr(vector, 'normed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix spark bug\n",
    "#Ref:https://www.cnblogs.com/bonelee/p/10976253.html\n",
    "matrix.sql_ctx.sparkSession._jsparkSession = spark._jsparkSession\n",
    "matrix._sc = spark._sc\n",
    "corrmatrix = matrix.collect()[0][0].toArray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>descendants</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>text_length</th>\n",
       "      <th>title_hot_words</th>\n",
       "      <th>title_vec</th>\n",
       "      <th>active_user</th>\n",
       "      <th>from_top_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>-0.007856</td>\n",
       "      <td>-0.001137</td>\n",
       "      <td>-0.036419</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>0.023420</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>0.011461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descendants</th>\n",
       "      <td>0.008808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008611</td>\n",
       "      <td>-0.140630</td>\n",
       "      <td>-0.102557</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>-0.028228</td>\n",
       "      <td>-0.134061</td>\n",
       "      <td>0.061733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayofweek</th>\n",
       "      <td>-0.007856</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>-0.008611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006231</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>-0.000560</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>-0.001137</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.140630</td>\n",
       "      <td>-0.006231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>-0.010427</td>\n",
       "      <td>-0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>-0.036419</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>-0.102557</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034018</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>-0.085365</td>\n",
       "      <td>-0.067538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_hot_words</th>\n",
       "      <td>0.005488</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>-0.000560</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>-0.034018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077690</td>\n",
       "      <td>-0.033775</td>\n",
       "      <td>0.028547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_vec</th>\n",
       "      <td>0.023420</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.028228</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>-0.077690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036292</td>\n",
       "      <td>-0.047040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active_user</th>\n",
       "      <td>-0.001841</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.134061</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-0.010427</td>\n",
       "      <td>-0.085365</td>\n",
       "      <td>-0.033775</td>\n",
       "      <td>-0.036292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_top_web</th>\n",
       "      <td>0.011461</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.061733</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.067538</td>\n",
       "      <td>0.028547</td>\n",
       "      <td>-0.047040</td>\n",
       "      <td>0.057090</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    score  descendants      year  dayofweek     month  \\\n",
       "score            1.000000     0.008808  0.049505  -0.007856 -0.001137   \n",
       "descendants      0.008808     1.000000  0.000111   0.000832 -0.000591   \n",
       "year             0.049505     0.000111  1.000000  -0.008611 -0.140630   \n",
       "dayofweek       -0.007856     0.000832 -0.008611   1.000000 -0.006231   \n",
       "month           -0.001137    -0.000591 -0.140630  -0.006231  1.000000   \n",
       "text_length     -0.036419     0.001905 -0.102557   0.014633  0.002194   \n",
       "title_hot_words  0.005488    -0.000309  0.034602  -0.000560 -0.007511   \n",
       "title_vec        0.023420     0.000180 -0.028228   0.005950  0.004458   \n",
       "active_user     -0.001841    -0.000714 -0.134061  -0.000506 -0.010427   \n",
       "from_top_web     0.011461    -0.000218  0.061733   0.000444 -0.000185   \n",
       "\n",
       "                 text_length  title_hot_words  title_vec  active_user  \\\n",
       "score              -0.036419         0.005488   0.023420    -0.001841   \n",
       "descendants         0.001905        -0.000309   0.000180    -0.000714   \n",
       "year               -0.102557         0.034602  -0.028228    -0.134061   \n",
       "dayofweek           0.014633        -0.000560   0.005950    -0.000506   \n",
       "month               0.002194        -0.007511   0.004458    -0.010427   \n",
       "text_length         1.000000        -0.034018   0.069131    -0.085365   \n",
       "title_hot_words    -0.034018         1.000000  -0.077690    -0.033775   \n",
       "title_vec           0.069131        -0.077690   1.000000    -0.036292   \n",
       "active_user        -0.085365        -0.033775  -0.036292     1.000000   \n",
       "from_top_web       -0.067538         0.028547  -0.047040     0.057090   \n",
       "\n",
       "                 from_top_web  \n",
       "score                0.011461  \n",
       "descendants         -0.000218  \n",
       "year                 0.061733  \n",
       "dayofweek            0.000444  \n",
       "month               -0.000185  \n",
       "text_length         -0.067538  \n",
       "title_hot_words      0.028547  \n",
       "title_vec           -0.047040  \n",
       "active_user          0.057090  \n",
       "from_top_web         1.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = pd.DataFrame(corrmatrix)\n",
    "corr_df.index, corr_df.columns = cols, cols\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- score: integer (nullable = true)\n",
      " |-- descendants: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofweek: integer (nullable = true)\n",
      " |-- active_user: double (nullable = true)\n",
      " |-- title_length: integer (nullable = true)\n",
      " |-- from_top_web: double (nullable = true)\n",
      " |-- text_length: integer (nullable = true)\n",
      " |-- title_hot_words: integer (nullable = true)\n",
      " |-- title_array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title_vec: float (nullable = true)\n",
      " |-- if_highscore: integer (nullable = true)\n",
      " |-- score_scaled: double (nullable = true)\n",
      " |-- if_highscore_scaled: integer (nullable = true)\n",
      " |-- des_scaled: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "1296793\n",
      "324443\n"
     ]
    }
   ],
   "source": [
    "#Tranform features and split data\n",
    "lin_cols = ['descendants', 'year', 'dayofweek', 'month', 'text_length', 'title_hot_words', 'title_vec']\n",
    "\n",
    "features = VectorAssembler(inputCols=lin_cols\n",
    "    , outputCol=\"features\")\n",
    "\n",
    "lr_feat = features.transform(change)\n",
    "lr_feat.printSchema()\n",
    "\n",
    "splitted_data = lr_feat.randomSplit([0.8, 0.2], 24)\n",
    "train = splitted_data[0]\n",
    "test = splitted_data[1]\n",
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #这个是 normalize 了 features 的\n",
    "# #import pyspark.ml.regression as rg\n",
    "# Scale numeric variables first \n",
    "\n",
    "# lin_cols = ['descendants', 'year', 'dayofweek', 'month', 'text_length', 'title_hot_words', 'title_vec']\n",
    "# scale_feat = VectorAssembler(inputCols=lin_cols\n",
    "#     , outputCol=\"norm\")\n",
    "\n",
    "# features = VectorAssembler(inputCols=['normed']\n",
    "#     , outputCol=\"features\")\n",
    "\n",
    "# norm = StandardScaler(inputCol='norm',\n",
    "#                     outputCol='normed')\n",
    "\n",
    "# score_feat = VectorAssembler(inputCols=['score']\n",
    "#     , outputCol=\"score_feat\")\n",
    "\n",
    "# score_norm = StandardScaler(inputCol='score_feat',\n",
    "#                     outputCol='score_normed')\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     stages=[\n",
    "#         scale_feat\n",
    "#         , score_feat\n",
    "#         , score_norm\n",
    "#         , norm\n",
    "#         , features\n",
    "#     ])\n",
    "\n",
    "# lr_feat = pipeline.fit(change).transform(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalize feature\n",
    "# lr_feat =  lr_feat.withColumn('score_normed', convert(\"score_normed\"))\n",
    "# lr_feat.printSchema()\n",
    "\n",
    "# splitted_data = lr_feat.randomSplit([0.8, 0.2], 24)\n",
    "# train = splitted_data[0]\n",
    "# test = splitted_data[1]\n",
    "# print(train.count())\n",
    "# print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit linear regression model\n",
    "lr_obj = rg.LinearRegression(\n",
    "    maxIter=10\n",
    "    , regParam=0.01\n",
    "    , elasticNetParam=1.00\n",
    "    , labelCol = 'score')\n",
    "lr_model =  lr_obj.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00426367869877331 42.4308516092833 15.657403785230473\n"
     ]
    }
   ],
   "source": [
    "#Get model data\n",
    "summary = lr_model.summary\n",
    "\n",
    "print(\n",
    "    summary.r2\n",
    "    , summary.rootMeanSquaredError\n",
    "    , summary.meanAbsoluteError\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.00469586\n"
     ]
    }
   ],
   "source": [
    "#Predict and evaluate model\n",
    "lr_predictions = lr_model.transform(test)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"score\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build k-means model\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols= cols\n",
    "    , outputCol='features')\n",
    "\n",
    "kmeans_obj = clust.KMeans(k=5, seed=666)\n",
    "\n",
    "kmeans_data = vectorAssembler.transform(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296855\n",
      "324381\n"
     ]
    }
   ],
   "source": [
    "#Split data\n",
    "splitted_data = kmeans_data.randomSplit([0.8, 0.2], 24)\n",
    "train = splitted_data[0]\n",
    "test = splitted_data[1]\n",
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|[1.0,-1.0,2011.0,...|         0|\n",
      "|[1.0,-1.0,2009.0,...|         0|\n",
      "|[1.0,-1.0,2011.0,...|         0|\n",
      "|[1.0,-1.0,2011.0,...|         0|\n",
      "|[1.0,-1.0,2011.0,...|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get kmeans result\n",
    "results = (\n",
    "    kmeans_obj\n",
    "    .fit(train)\n",
    "    .transform(test)\n",
    "    .select('features', 'prediction')\n",
    ")\n",
    "\n",
    "results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322713415689663"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate kmeans model performance\n",
    "clustering_ev = ClusteringEvaluator()\n",
    "clustering_ev.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[3.75706087e+00 8.11430996e-01 2.01201610e+03 3.99475979e+00\n",
      " 6.43605662e+00 2.25988702e+00 4.15220888e-01 1.79913875e-01\n",
      " 4.63950981e-01 2.64218020e-01]\n",
      "[1.00000000e+00 2.37210300e+06 2.01100000e+03 6.00000000e+00\n",
      " 4.00000000e+00 3.70000000e+01 0.00000000e+00 1.30351201e-01\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "[7.56431357e+02 2.64022746e+02 2.01312998e+03 3.88383428e+00\n",
      " 6.31356621e+00 3.60682372e-01 4.06986190e-01 1.99093302e-01\n",
      " 3.82615760e-01 2.73761170e-01]\n",
      "[2.78486291e+02 1.24671569e+02 2.01286374e+03 3.94026255e+00\n",
      " 6.36665005e+00 3.03423064e-01 4.31040213e-01 1.89016017e-01\n",
      " 4.34446660e-01 2.83649053e-01]\n",
      "[9.03691200e+01 4.50790665e+01 2.01239419e+03 3.93944900e+00\n",
      " 6.45897199e+00 2.94826903e-01 4.39349894e-01 1.81391813e-01\n",
      " 4.79436443e-01 2.91308800e-01]\n"
     ]
    }
   ],
   "source": [
    "#Get cluster center data\n",
    "model = kmeans_obj.fit(train)\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode variables\n",
    "sI1 = StringIndexer(inputCol=\"active_user\", outputCol=\"active_userIndex\"); \n",
    "en1 = OneHotEncoder(dropLast=False, inputCol=\"active_userIndex\", outputCol=\"active_userVec\");\n",
    "sI2 = StringIndexer(inputCol=\"from_top_web\", outputCol=\"from_top_webIndex\"); \n",
    "en2 = OneHotEncoder(dropLast=False, inputCol=\"from_top_webIndex\", outputCol=\"from_top_webVec\");\n",
    "\n",
    "encodedFinal = Pipeline(stages=[sI1, en1, sI2, en2]).fit(data).transform(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 1135713\n",
      "Number of testing records : 485523\n"
     ]
    }
   ],
   "source": [
    "#Split dataset\n",
    "train_data, test_data = encodedFinal.randomSplit([0.7, 0.3], seed=1234);\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 24.91817371612741\n",
      "R-sqr = 0.3669494235262043\n"
     ]
    }
   ],
   "source": [
    "# using score\n",
    "\n",
    "\n",
    "# define fomular\n",
    "regFormula = RFormula(formula=\"score ~ des_scaled + year + month + dayofweek + title_length + text_length + title_hot_words + title_vec + active_userVec + from_top_webVec\")\n",
    "\n",
    "# define indexer for categorical variables\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", handleInvalid='skip', maxCategories=32)\n",
    "\n",
    "# define random forest estimator\n",
    "randForest = RandomForestRegressor(featuresCol = 'indexedFeatures', labelCol = 'label', numTrees=20, \n",
    "                                   featureSubsetStrategy=\"auto\",impurity='variance', maxDepth=8, maxBins=200)\n",
    "\n",
    "# fit model with formula and other ransformations\n",
    "model = Pipeline(stages=[regFormula, featureIndexer, randForest]).fit(train_data)\n",
    "# predict\n",
    "predictions = model.transform(test_data)\n",
    "predictionAndLabels = predictions.select(\"label\",\"prediction\").rdd\n",
    "\n",
    "testMetrics = RegressionMetrics(predictionAndLabels)\n",
    "print(\"RMSE = %s\" % testMetrics.rootMeanSquaredError)\n",
    "print(\"R-sqr = %s\" % testMetrics.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6628565631473219"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 1.0\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "\n",
    "classFormula = RFormula(formula=\"if_highscore_scaled ~ des_scaled + year + month + dayofweek + title_length + text_length + title_hot_words + title_vec + active_userVec + from_top_webVec\")\n",
    "\n",
    "\n",
    "model = Pipeline(stages=[classFormula, logReg]).fit(train_data)\n",
    "\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "predictionAndLabels = predictions.select(\"label\",\"prediction\").rdd\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
